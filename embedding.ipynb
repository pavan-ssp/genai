{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1baea2f",
   "metadata": {},
   "source": [
    "\n",
    "Encoding ---> conversion of words to vectors or numericals [ it depends on frequency of the words]\n",
    "              BOW , TF-IDF , OHE , N-grams , some custom techniques\n",
    "\t\t\t  \n",
    "Embedding ----> word into vectors [  it depends on frequency of the neural network architecture ]\n",
    "                word2vec introduced by google and it is used by using neuralnetwork by default it is consists of vector size of 384\n",
    "\t\t\t\t\n",
    "New technique -- > Transformers based models (sentence embedding)\n",
    "                   Bert , Gemini , Elmo , open ai , MPT\n",
    "\t\t\t\t   \n",
    "\t\t\t\t   \n",
    "Note : Difference between encoding and embedding are both are try to convert words into vectors or numericals but embedding is based on neuralnetwork architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40564ba5",
   "metadata": {},
   "source": [
    "### Embedding : [  it depends on frequency of the neural network architecture ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56e6193",
   "metadata": {},
   "source": [
    "\n",
    "1) Word2vec :  it is of 2 types CBOW and SKIPGRAM\n",
    "\n",
    "Google word2vec : It was developed by the google and it is based on the neural network architecture and it contains 300 dimensions of word (ie : it contains 300 vectors for each word)\n",
    "\n",
    "Based on the research if we have small data we can use \"CBOW\" and for large dataset we use \"SKIPGRAM\"\n",
    "\n",
    "Improvement in word2vec : Increase window size \n",
    "                          Increase dimension of vector\n",
    "\t\t\t\t\t\t  Increase the training dataset\n",
    "\t\t\t\t\t\t  \n",
    "2) Skipgram : \n",
    "\n",
    "3) Avgword2vec : it is used for sentences\n",
    "                 Average word2vec take average of all the words of the vectors  in the sentences and that value taken into consideration .\n",
    "\n",
    "\n",
    "Note : Sentence Embedding :\n",
    "---------------------------\n",
    " We can do sentence embedding means convert into vectors by 3 ways\n",
    " \n",
    " 1) sentence transformer\n",
    " \n",
    " 2) langchain hugging face models\n",
    " \n",
    " 3) Transformer based [Bert based]\n",
    " \n",
    " We can also decode the vectors ie: convert vectors into original form (sentences) .\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Common types of encoding:\n",
    "--------------------------\n",
    "\n",
    "Encoding Type\t                    Description\t                                                        Example\n",
    "One-Hot Encoding\t                Each word or category becomes a binary vector.\t                    \"cat\" → [0, 1, 0]\n",
    "Label Encoding\t                    Assigns an integer to each word/category.\t                        \"cat\" → 1\n",
    "Ordinal Encoding\t                Like label encoding, but assumes some order between categories.\t    \"low\" → 0, \"high\" → 2\n",
    "Frequency Encoding\t                Encodes based on frequency of the word/category in the data.\t    \"the\" → 5000\n",
    "\n",
    "\n",
    "\n",
    "Common types of Embedding:\n",
    "--------------------------\n",
    "\n",
    "Word2vec "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfac1c8",
   "metadata": {},
   "source": [
    "1) Word2vec :  it is of 2 types CBOW and SKIPGRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6800e5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.3-cp311-cp311-win_amd64.whl.metadata (8.2 kB)\n",
      "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
      "  Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
      "  Downloading scipy-1.13.1-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from gensim) (7.1.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
      "Downloading gensim-4.3.3-cp311-cp311-win_amd64.whl (24.0 MB)\n",
      "   ---------------------------------------- 0.0/24.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/24.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/24.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/24.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/24.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/24.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/24.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/24.0 MB 453.5 kB/s eta 0:00:52\n",
      "   - -------------------------------------- 0.8/24.0 MB 589.1 kB/s eta 0:00:40\n",
      "   - -------------------------------------- 1.0/24.0 MB 709.1 kB/s eta 0:00:33\n",
      "   -- ------------------------------------- 1.3/24.0 MB 799.2 kB/s eta 0:00:29\n",
      "   -- ------------------------------------- 1.6/24.0 MB 883.2 kB/s eta 0:00:26\n",
      "   --- ------------------------------------ 1.8/24.0 MB 923.6 kB/s eta 0:00:25\n",
      "   --- ------------------------------------ 2.1/24.0 MB 987.1 kB/s eta 0:00:23\n",
      "   --- ------------------------------------ 2.4/24.0 MB 1.0 MB/s eta 0:00:21\n",
      "   ---- ----------------------------------- 2.6/24.0 MB 1.1 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 3.1/24.0 MB 1.1 MB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 3.4/24.0 MB 1.2 MB/s eta 0:00:18\n",
      "   ------ --------------------------------- 3.9/24.0 MB 1.2 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 4.5/24.0 MB 1.3 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 5.0/24.0 MB 1.4 MB/s eta 0:00:14\n",
      "   -------- ------------------------------- 5.2/24.0 MB 1.4 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 5.8/24.0 MB 1.5 MB/s eta 0:00:13\n",
      "   ---------- ----------------------------- 6.3/24.0 MB 1.5 MB/s eta 0:00:12\n",
      "   ---------- ----------------------------- 6.6/24.0 MB 1.5 MB/s eta 0:00:12\n",
      "   ----------- ---------------------------- 7.1/24.0 MB 1.6 MB/s eta 0:00:11\n",
      "   ------------ --------------------------- 7.6/24.0 MB 1.6 MB/s eta 0:00:11\n",
      "   ------------- -------------------------- 8.4/24.0 MB 1.7 MB/s eta 0:00:10\n",
      "   --------------- ------------------------ 9.2/24.0 MB 1.8 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 10.0/24.0 MB 1.9 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 10.7/24.0 MB 1.9 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 11.8/24.0 MB 2.0 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 12.6/24.0 MB 2.1 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 13.4/24.0 MB 2.1 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 13.9/24.0 MB 2.2 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 14.9/24.0 MB 2.2 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 15.7/24.0 MB 2.3 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 16.5/24.0 MB 2.3 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 17.3/24.0 MB 2.4 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 18.1/24.0 MB 2.4 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 18.9/24.0 MB 2.5 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 19.7/24.0 MB 2.5 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 20.4/24.0 MB 2.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 21.2/24.0 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 22.0/24.0 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 22.8/24.0 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  23.6/24.0 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.0/24.0 MB 2.6 MB/s eta 0:00:00\n",
      "Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.0/15.8 MB 5.0 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.8/15.8 MB 4.4 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 2.6/15.8 MB 4.2 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 3.4/15.8 MB 4.0 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 4.2/15.8 MB 4.0 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 5.0/15.8 MB 4.0 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 5.8/15.8 MB 3.9 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 6.8/15.8 MB 3.9 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 7.6/15.8 MB 3.9 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 8.1/15.8 MB 3.9 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 8.7/15.8 MB 3.7 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 9.4/15.8 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 10.2/15.8 MB 3.7 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 10.7/15.8 MB 3.6 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 11.5/15.8 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 12.1/15.8 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 12.6/15.8 MB 3.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 13.1/15.8 MB 3.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 13.9/15.8 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.7/15.8 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.8 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 3.4 MB/s eta 0:00:00\n",
      "Downloading scipy-1.13.1-cp311-cp311-win_amd64.whl (46.2 MB)\n",
      "   ---------------------------------------- 0.0/46.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 1.0/46.2 MB 4.2 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 1.8/46.2 MB 4.0 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 2.6/46.2 MB 4.0 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 3.4/46.2 MB 3.9 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 3.9/46.2 MB 3.7 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 4.5/46.2 MB 3.4 MB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 5.0/46.2 MB 3.4 MB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 5.8/46.2 MB 3.4 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 6.6/46.2 MB 3.4 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 7.3/46.2 MB 3.5 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 8.1/46.2 MB 3.5 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 8.9/46.2 MB 3.5 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 9.7/46.2 MB 3.6 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 10.5/46.2 MB 3.6 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 11.3/46.2 MB 3.6 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 12.1/46.2 MB 3.6 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 12.8/46.2 MB 3.6 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 13.4/46.2 MB 3.5 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 14.4/46.2 MB 3.7 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 15.2/46.2 MB 3.6 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 16.0/46.2 MB 3.6 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 16.8/46.2 MB 3.6 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 17.6/46.2 MB 3.6 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 18.4/46.2 MB 3.6 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 19.1/46.2 MB 3.6 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 19.9/46.2 MB 3.6 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 20.7/46.2 MB 3.6 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 21.5/46.2 MB 3.7 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 22.3/46.2 MB 3.7 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 23.1/46.2 MB 3.7 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 23.9/46.2 MB 3.7 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 24.6/46.2 MB 3.7 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 25.7/46.2 MB 3.7 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 26.2/46.2 MB 3.7 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 27.0/46.2 MB 3.7 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 27.8/46.2 MB 3.7 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 28.3/46.2 MB 3.7 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 29.1/46.2 MB 3.6 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 29.9/46.2 MB 3.6 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 30.4/46.2 MB 3.6 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 31.2/46.2 MB 3.6 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 32.0/46.2 MB 3.6 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 32.8/46.2 MB 3.6 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 33.6/46.2 MB 3.6 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 34.3/46.2 MB 3.7 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 35.1/46.2 MB 3.6 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 35.9/46.2 MB 3.7 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 36.4/46.2 MB 3.6 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 37.2/46.2 MB 3.6 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 38.0/46.2 MB 3.6 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 38.8/46.2 MB 3.6 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 39.8/46.2 MB 3.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 40.6/46.2 MB 3.6 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 41.4/46.2 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 42.2/46.2 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 43.0/46.2 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 43.8/46.2 MB 3.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 44.6/46.2 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.4/46.2 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  46.1/46.2 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 46.2/46.2 MB 3.6 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy, scipy, gensim\n",
      "\n",
      "  Attempting uninstall: numpy\n",
      "\n",
      "    Found existing installation: numpy 2.2.5\n",
      "\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "    Uninstalling numpy-2.2.5:\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "      Successfully uninstalled numpy-2.2.5\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "  Attempting uninstall: scipy\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "    Found existing installation: scipy 1.15.3\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "    Uninstalling scipy-1.15.3:\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "      Successfully uninstalled scipy-1.15.3\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   -------------------------- ------------- 2/3 [gensim]\n",
      "   -------------------------- ------------- 2/3 [gensim]\n",
      "   -------------------------- ------------- 2/3 [gensim]\n",
      "   -------------------------- ------------- 2/3 [gensim]\n",
      "   -------------------------- ------------- 2/3 [gensim]\n",
      "   ---------------------------------------- 3/3 [gensim]\n",
      "\n",
      "Successfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\chand\\anaconda3\\envs\\env\\Lib\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\chand\\anaconda3\\envs\\env\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\chand\\anaconda3\\envs\\env\\Lib\\site-packages\\~cipy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\chand\\anaconda3\\envs\\env\\Lib\\site-packages\\~cipy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59263c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec,KeyedVectors\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0dfa0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "690abfa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.12597656, -0.015625  ,  0.22949219,  0.13964844,  0.05053711,\n",
       "        0.14550781,  0.27929688, -0.00130463, -0.13183594,  0.12353516,\n",
       "       -0.10644531, -0.07275391, -0.22167969,  0.34375   , -0.19140625,\n",
       "        0.21875   ,  0.11181641, -0.0168457 , -0.04418945, -0.03979492,\n",
       "       -0.06591797, -0.17089844,  0.10205078,  0.0145874 , -0.14355469,\n",
       "       -0.05102539, -0.0234375 ,  0.00616455,  0.12988281, -0.16113281,\n",
       "       -0.05810547, -0.140625  , -0.08837891,  0.07714844, -0.09863281,\n",
       "       -0.05200195, -0.0189209 , -0.0625    ,  0.19824219, -0.05395508,\n",
       "        0.02172852, -0.06079102,  0.06640625,  0.05273438, -0.08642578,\n",
       "       -0.11865234, -0.22363281, -0.05493164, -0.07421875, -0.03979492,\n",
       "       -0.04736328,  0.21679688, -0.02526855,  0.05395508,  0.08886719,\n",
       "        0.11816406, -0.14257812, -0.31640625,  0.08251953, -0.16992188,\n",
       "        0.15527344,  0.15234375,  0.17480469, -0.04785156,  0.06054688,\n",
       "       -0.08544922,  0.03540039,  0.04272461,  0.14941406,  0.0078125 ,\n",
       "        0.02844238,  0.05541992,  0.02807617,  0.0300293 , -0.09375   ,\n",
       "       -0.22753906,  0.04150391,  0.0267334 ,  0.13867188, -0.07617188,\n",
       "       -0.02954102,  0.07275391, -0.04003906, -0.14453125, -0.0267334 ,\n",
       "       -0.00592041,  0.00787354,  0.13085938,  0.10253906,  0.01470947,\n",
       "       -0.04711914, -0.03857422,  0.02319336, -0.12060547, -0.16503906,\n",
       "       -0.00091171,  0.02331543, -0.03417969,  0.2734375 , -0.14160156,\n",
       "        0.03979492,  0.02368164,  0.23046875, -0.08105469, -0.04711914,\n",
       "       -0.02404785, -0.16308594,  0.2109375 ,  0.01879883, -0.04980469,\n",
       "       -0.07861328,  0.0859375 ,  0.07226562, -0.11230469,  0.10449219,\n",
       "        0.1796875 ,  0.06054688, -0.13964844,  0.09033203,  0.12792969,\n",
       "        0.21582031,  0.22265625, -0.20507812,  0.05151367, -0.234375  ,\n",
       "        0.07080078, -0.04956055,  0.03613281,  0.15917969,  0.04272461,\n",
       "       -0.1796875 , -0.03112793, -0.11816406, -0.0859375 , -0.06933594,\n",
       "        0.05737305,  0.09716797, -0.078125  ,  0.125     ,  0.07958984,\n",
       "        0.09912109, -0.04614258, -0.02368164, -0.14941406, -0.296875  ,\n",
       "        0.00921631,  0.01660156, -0.01116943,  0.14746094,  0.00958252,\n",
       "        0.11279297, -0.10693359, -0.09570312,  0.05151367, -0.08642578,\n",
       "       -0.22460938, -0.21972656,  0.02441406,  0.11962891, -0.00146484,\n",
       "        0.06640625, -0.01843262,  0.08056641, -0.00135803, -0.07910156,\n",
       "       -0.05493164,  0.09960938,  0.04150391, -0.12988281, -0.00141144,\n",
       "       -0.04077148, -0.09423828, -0.11132812, -0.02636719, -0.01623535,\n",
       "       -0.08935547,  0.20703125, -0.10546875, -0.02233887, -0.35742188,\n",
       "        0.04492188,  0.16601562, -0.05419922, -0.15625   , -0.04101562,\n",
       "        0.06298828, -0.10986328, -0.0546875 ,  0.17285156,  0.13867188,\n",
       "       -0.02001953,  0.18164062, -0.12988281,  0.09716797,  0.05810547,\n",
       "       -0.08740234,  0.06103516,  0.04614258,  0.0168457 ,  0.0111084 ,\n",
       "       -0.03417969, -0.04003906, -0.07080078, -0.17675781,  0.11132812,\n",
       "       -0.1484375 , -0.02490234,  0.012146  ,  0.00653076, -0.23242188,\n",
       "       -0.06738281,  0.07226562, -0.07519531, -0.17578125,  0.0859375 ,\n",
       "        0.0098877 , -0.07666016,  0.03637695, -0.10791016, -0.14355469,\n",
       "        0.10107422,  0.06298828,  0.19140625,  0.16699219, -0.0055542 ,\n",
       "        0.00180817,  0.1171875 ,  0.02563477,  0.04443359,  0.15625   ,\n",
       "       -0.0123291 ,  0.06542969, -0.00098419,  0.11425781,  0.14746094,\n",
       "       -0.05273438,  0.15136719,  0.09130859, -0.10791016,  0.10791016,\n",
       "        0.19140625,  0.02746582,  0.16601562, -0.0112915 , -0.12695312,\n",
       "        0.07861328,  0.02246094,  0.17089844,  0.01275635, -0.04907227,\n",
       "        0.16113281,  0.07666016,  0.12158203,  0.06689453,  0.10302734,\n",
       "       -0.12988281,  0.00364685, -0.18164062,  0.08789062, -0.17578125,\n",
       "       -0.02770996,  0.00619507, -0.00396729, -0.18457031, -0.02526855,\n",
       "        0.078125  ,  0.2421875 , -0.08203125,  0.03686523, -0.16601562,\n",
       "       -0.11376953, -0.09179688, -0.15136719,  0.05249023,  0.2109375 ,\n",
       "        0.05126953, -0.21777344, -0.07666016, -0.15136719,  0.22851562,\n",
       "       -0.14550781, -0.04296875, -0.04711914, -0.09082031,  0.16503906,\n",
       "       -0.00427246, -0.10351562,  0.11621094, -0.02001953,  0.05029297,\n",
       "        0.00717163,  0.05541992, -0.02209473, -0.01422119, -0.17382812,\n",
       "       -0.125     , -0.15527344, -0.12890625, -0.09619141,  0.29101562],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[\"satya\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2287a064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model[\"satya\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "794be254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.78515625e-02,  1.66992188e-01,  7.81250000e-02,  2.10571289e-03,\n",
       "        2.25585938e-01, -2.25585938e-01, -2.09960938e-01, -3.73535156e-02,\n",
       "       -1.85546875e-02,  1.94335938e-01, -3.00292969e-02, -1.77734375e-01,\n",
       "        5.20019531e-02,  1.33789062e-01, -1.13769531e-01,  1.10351562e-01,\n",
       "       -3.27148438e-02,  2.89916992e-03,  9.88769531e-03,  9.27734375e-02,\n",
       "       -2.19726562e-01, -2.47802734e-02, -8.59375000e-02, -2.67578125e-01,\n",
       "       -2.51464844e-02, -2.55859375e-01, -1.61132812e-01,  2.53906250e-01,\n",
       "        5.24902344e-02, -1.00097656e-02,  1.82617188e-01,  7.61718750e-02,\n",
       "       -1.60980225e-03, -3.10058594e-02, -3.32031250e-02,  1.81640625e-01,\n",
       "       -3.88183594e-02, -1.83593750e-01, -8.64257812e-02,  2.20703125e-01,\n",
       "       -7.11059570e-03,  8.60595703e-03,  1.73828125e-01, -9.27734375e-02,\n",
       "        1.25000000e-01, -1.28906250e-01, -4.85839844e-02, -1.21093750e-01,\n",
       "        8.00781250e-02,  1.05957031e-01,  1.42578125e-01,  6.78710938e-02,\n",
       "        6.29882812e-02, -2.60009766e-02,  1.12304688e-01, -3.08593750e-01,\n",
       "       -1.98364258e-03,  2.46582031e-02, -1.57226562e-01,  8.54492188e-02,\n",
       "        3.97949219e-02,  1.41601562e-01, -1.20117188e-01, -2.69775391e-02,\n",
       "        6.78710938e-02, -3.73840332e-03, -5.12695312e-02,  1.33666992e-02,\n",
       "        6.17675781e-02,  2.72216797e-02, -1.22558594e-01,  1.54296875e-01,\n",
       "       -1.24511719e-01,  8.00781250e-02, -4.49218750e-02, -9.47265625e-02,\n",
       "       -1.00585938e-01,  1.16210938e-01, -1.83593750e-01,  4.00390625e-02,\n",
       "        7.91015625e-02, -1.30859375e-01,  5.00488281e-02,  9.22851562e-02,\n",
       "       -2.77343750e-01, -1.40625000e-01, -2.69531250e-01, -7.81250000e-02,\n",
       "        1.41601562e-02,  4.34570312e-02, -2.75390625e-01, -9.76562500e-02,\n",
       "       -1.57470703e-02, -6.29425049e-05,  1.63085938e-01, -1.83593750e-01,\n",
       "       -2.05078125e-02, -1.49414062e-01,  6.05468750e-02, -1.60156250e-01,\n",
       "        6.13403320e-03, -1.65039062e-01,  2.32696533e-04, -1.13281250e-01,\n",
       "        2.29492188e-01, -3.80859375e-02,  1.26953125e-01,  2.45361328e-02,\n",
       "        1.66992188e-01,  3.01513672e-02,  1.60156250e-01,  1.56250000e-01,\n",
       "       -7.12890625e-02,  1.08886719e-01, -2.58789062e-02, -4.41894531e-02,\n",
       "        1.51367188e-01, -1.06933594e-01,  6.29882812e-02,  1.42578125e-01,\n",
       "       -3.06640625e-01,  7.47070312e-02, -3.83300781e-02, -1.48437500e-01,\n",
       "       -2.16796875e-01, -1.51367188e-01,  8.42285156e-03,  2.04101562e-01,\n",
       "        1.58203125e-01,  2.63671875e-01, -1.09863281e-01, -3.41796875e-01,\n",
       "       -1.21093750e-01,  6.59179688e-02, -5.83496094e-02,  8.10546875e-02,\n",
       "        4.93164062e-02,  4.02832031e-02,  3.02124023e-03, -4.99725342e-04,\n",
       "        8.72802734e-03, -1.43554688e-01,  3.20312500e-01,  6.03027344e-02,\n",
       "       -1.53320312e-01,  2.83203125e-01, -7.17773438e-02, -6.86645508e-03,\n",
       "       -9.22851562e-02,  2.72216797e-02,  7.66601562e-02, -6.49414062e-02,\n",
       "       -1.94335938e-01, -2.40234375e-01,  1.59179688e-01,  2.81250000e-01,\n",
       "       -1.71875000e-01, -4.02832031e-02,  1.00097656e-01, -1.30859375e-01,\n",
       "       -5.95703125e-02,  8.48388672e-03,  9.96093750e-02,  3.97949219e-02,\n",
       "        2.11181641e-02, -2.59765625e-01,  1.25000000e-01,  1.61132812e-01,\n",
       "        3.14941406e-02, -4.39453125e-02,  1.38671875e-01, -1.11328125e-01,\n",
       "       -5.20019531e-02, -8.10546875e-02,  7.71484375e-02, -8.39843750e-02,\n",
       "        9.27734375e-02, -4.37011719e-02, -1.87500000e-01, -1.35742188e-01,\n",
       "        2.32421875e-01, -1.72119141e-02, -1.27929688e-01, -1.03027344e-01,\n",
       "       -2.11914062e-01, -8.88671875e-02,  2.53906250e-01,  1.52343750e-01,\n",
       "        1.25000000e-01,  1.80664062e-01,  8.98437500e-02, -6.29882812e-02,\n",
       "        6.78710938e-02,  1.57226562e-01, -5.95703125e-02,  3.26538086e-03,\n",
       "        1.81640625e-01,  8.10546875e-02, -2.77343750e-01, -3.80859375e-02,\n",
       "       -7.56835938e-02, -1.09863281e-01, -1.08398438e-01, -1.46484375e-01,\n",
       "        1.36718750e-02, -1.67236328e-02,  5.51757812e-02, -7.27539062e-02,\n",
       "       -1.69921875e-01, -1.34765625e-01,  6.25610352e-03, -1.11328125e-01,\n",
       "       -2.24609375e-02,  1.18164062e-01, -2.42187500e-01, -1.88476562e-01,\n",
       "       -1.57226562e-01,  9.47265625e-02, -1.84570312e-01,  1.85546875e-01,\n",
       "       -1.05468750e-01, -1.71875000e-01,  2.51953125e-01, -1.49414062e-01,\n",
       "       -1.28936768e-03, -6.78710938e-02,  2.06054688e-01, -9.96093750e-02,\n",
       "       -7.42187500e-02, -1.10351562e-01,  1.42578125e-01, -3.03955078e-02,\n",
       "       -9.03320312e-02,  2.47070312e-01,  1.38854980e-03, -2.24609375e-01,\n",
       "       -1.04003906e-01,  1.06445312e-01,  1.80664062e-01, -7.47680664e-03,\n",
       "        1.25976562e-01, -5.32226562e-02, -2.57812500e-01, -8.49609375e-02,\n",
       "        4.94384766e-03,  5.17578125e-02, -1.02539062e-01,  1.44531250e-01,\n",
       "       -1.47460938e-01,  1.17675781e-01,  2.83203125e-01,  1.45507812e-01,\n",
       "       -8.78906250e-02, -9.32617188e-02,  8.00781250e-02, -1.83105469e-02,\n",
       "        3.46679688e-02, -8.54492188e-02,  1.16210938e-01,  1.50390625e-01,\n",
       "        5.49316406e-02, -2.38281250e-01,  7.27539062e-02, -5.59082031e-02,\n",
       "        5.02929688e-02,  2.13867188e-01, -1.66015625e-01,  3.83300781e-02,\n",
       "        3.11279297e-02,  2.50000000e-01, -7.12890625e-02,  2.42187500e-01,\n",
       "       -1.26953125e-01,  5.95703125e-02,  2.77343750e-01,  3.61328125e-02,\n",
       "       -1.97753906e-02, -2.22656250e-01,  5.76171875e-02,  1.45507812e-01,\n",
       "        9.81445312e-02, -2.75390625e-01,  7.22656250e-02,  1.31835938e-01,\n",
       "       -8.44726562e-02, -8.39843750e-02, -1.08398438e-01, -8.49609375e-02,\n",
       "        1.38671875e-01,  1.14257812e-01,  1.11816406e-01,  1.29882812e-01,\n",
       "       -8.69140625e-02, -2.23632812e-01,  1.13281250e-01, -8.85009766e-03,\n",
       "       -4.83398438e-02, -2.91015625e-01,  4.46777344e-02,  1.61132812e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[\"men\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3773369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model[\"men\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82718ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('woman', 0.7664012908935547),\n",
       " ('boy', 0.6824871301651001),\n",
       " ('teenager', 0.6586930155754089),\n",
       " ('teenage_girl', 0.6147903203964233),\n",
       " ('girl', 0.5921714305877686),\n",
       " ('suspected_purse_snatcher', 0.571636438369751),\n",
       " ('robber', 0.5585119128227234),\n",
       " ('Robbery_suspect', 0.5584409832954407),\n",
       " ('teen_ager', 0.5549196600914001),\n",
       " ('men', 0.5489763021469116)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"man\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00b4a4d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cricketing', 0.8372225761413574),\n",
       " ('cricketers', 0.8165745735168457),\n",
       " ('Test_cricket', 0.8094819188117981),\n",
       " ('Twenty##_cricket', 0.8068488240242004),\n",
       " ('Twenty##', 0.7624265551567078),\n",
       " ('Cricket', 0.75413978099823),\n",
       " ('cricketer', 0.7372578382492065),\n",
       " ('twenty##', 0.7316356897354126),\n",
       " ('T##_cricket', 0.7304614186286926),\n",
       " ('West_Indies_cricket', 0.6987985968589783)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"cricket\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c22bc18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('atma', 0.7216063141822815),\n",
       " ('smriti', 0.6725621819496155),\n",
       " ('dharam', 0.6696865558624268),\n",
       " ('Shri_Rama', 0.6682771444320679),\n",
       " ('kriya', 0.6587613224983215),\n",
       " ('mukti', 0.6582211852073669),\n",
       " ('Adhyatma', 0.6546815633773804),\n",
       " ('Gurbaani', 0.6518490314483643),\n",
       " ('Bhagwad_Geeta', 0.6501480340957642),\n",
       " ('ka_hai', 0.6466910243034363)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"satya\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "467ee3d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76640123"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('man','woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90c79b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2097966"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('man','python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8f5fd17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.019312028"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('man','java')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d218e0e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43010473"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('sunny','Sunny')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5577296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DOG'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match([\"PHP\",\"JAVA\",\"DOG\",\"C++\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1615cc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec=model['king'] - model['man'] + model['woman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fece8930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('king', 0.8449392318725586),\n",
       " ('queen', 0.7300517559051514),\n",
       " ('monarch', 0.645466148853302),\n",
       " ('princess', 0.6156251430511475),\n",
       " ('crown_prince', 0.5818676352500916),\n",
       " ('prince', 0.5777117609977722),\n",
       " ('kings', 0.5613663792610168),\n",
       " ('sultan', 0.5376775860786438),\n",
       " ('Queen_Consort', 0.5344247817993164),\n",
       " ('queens', 0.5289887189865112)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar([vec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d2ac05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\chand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\chand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['war', 'vikram', 'everything', 'changes', 'warrior', 'brave', 'went']\n",
      "\n",
      "Vector for 'war': [-5.3622725e-04  2.3643136e-04  5.1033497e-03  9.0092728e-03\n",
      " -9.3029495e-03 -7.1168090e-03  6.4588725e-03  8.9729885e-03\n",
      " -5.0154282e-03 -3.7633716e-03  7.3805046e-03 -1.5334714e-03\n",
      " -4.5366134e-03  6.5540518e-03 -4.8601604e-03 -1.8160177e-03\n",
      "  2.8765798e-03  9.9187379e-04 -8.2852151e-03 -9.4488179e-03\n",
      "  7.3117660e-03  5.0702621e-03  6.7576934e-03  7.6286553e-04\n",
      "  6.3508903e-03 -3.4053659e-03 -9.4640139e-04  5.7685734e-03\n",
      " -7.5216377e-03 -3.9361035e-03 -7.5115822e-03 -9.3004224e-04\n",
      "  9.5381187e-03 -7.3191668e-03 -2.3337686e-03 -1.9377411e-03\n",
      "  8.0774371e-03 -5.9308959e-03  4.5162440e-05 -4.7537340e-03\n",
      " -9.6035507e-03  5.0072931e-03 -8.7595852e-03 -4.3918253e-03\n",
      " -3.5099984e-05 -2.9618145e-04 -7.6612402e-03  9.6147433e-03\n",
      "  4.9820580e-03  9.2331432e-03 -8.1579173e-03  4.4957981e-03\n",
      " -4.1370760e-03  8.2453608e-04  8.4986202e-03 -4.4621765e-03\n",
      "  4.5175003e-03 -6.7869602e-03 -3.5484887e-03  9.3985079e-03\n",
      " -1.5776526e-03  3.2137157e-04 -4.1406299e-03 -7.6826881e-03\n",
      " -1.5080082e-03  2.4697948e-03 -8.8802696e-04  5.5336617e-03\n",
      " -2.7429771e-03  2.2600652e-03  5.4557943e-03  8.3459532e-03\n",
      " -1.4537406e-03 -9.2081428e-03  4.3705525e-03  5.7178497e-04\n",
      "  7.4419081e-03 -8.1328274e-04 -2.6384138e-03 -8.7530091e-03\n",
      " -8.5655687e-04  2.8265631e-03  5.4014288e-03  7.0526563e-03\n",
      " -5.7031214e-03  1.8588197e-03  6.0888636e-03 -4.7980510e-03\n",
      " -3.1072604e-03  6.7976294e-03  1.6314756e-03  1.8991709e-04\n",
      "  3.4736372e-03  2.1777749e-04  9.6188262e-03  5.0606038e-03\n",
      " -8.9173904e-03 -7.0415605e-03  9.0145587e-04  6.3925339e-03]\n",
      "\n",
      "Words most similar to 'vikram':\n",
      "changes: 0.0680\n",
      "brave: 0.0094\n",
      "warrior: 0.0045\n",
      "war: -0.0108\n",
      "everything: -0.0237\n",
      "went: -0.1141\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "# Download required resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Sample text data (replace this with your own text corpus)\n",
    "text = \"Vikram went to war. Vikram is a brave warrior. War changes everything.\"\n",
    "\n",
    "# Sentence tokenization\n",
    "sentences = sent_tokenize(text)\n",
    "\n",
    "# Word tokenization and stopword removal\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokenized_sentences = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    words = word_tokenize(sentence.lower())\n",
    "    filtered_words = [word for word in words if word.isalpha() and word not in stop_words]\n",
    "    tokenized_sentences.append(filtered_words)\n",
    "\n",
    "# Train Word2Vec model\n",
    "model = Word2Vec(sentences=tokenized_sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Words in vocabulary (note: `wv.vocab` is deprecated)\n",
    "words = list(model.wv.index_to_key)\n",
    "print(\"Vocabulary:\", words)\n",
    "\n",
    "# Find vector of a word\n",
    "if 'war' in model.wv:\n",
    "    vector = model.wv['war']\n",
    "    print(\"\\nVector for 'war':\", vector)\n",
    "\n",
    "# Find most similar words\n",
    "if 'vikram' in model.wv:\n",
    "    similar = model.wv.most_similar('vikram')\n",
    "    print(\"\\nWords most similar to 'vikram':\")\n",
    "    for word, score in similar:\n",
    "        print(f\"{word}: {score:.4f}\")\n",
    "else:\n",
    "    print(\"\\nWord 'vikram' not found in vocabulary.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23559842",
   "metadata": {},
   "source": [
    "Custom Word2vec model : \n",
    "--------------------------\n",
    "\n",
    "custom_model = gensim.models.word2vec( window =10,min_count=5,vector_size=150)\n",
    "\n",
    "here min_count represents if the word appear minimum 5 times then only consider that word otherwise reject the word .\n",
    "\n",
    "vector_size represents hiddenlayer vector size\n",
    "\n",
    "window represent choose a word [Target word]  so that the 10 words before and after are surrounded  by the selected  target word ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8ee925",
   "metadata": {},
   "source": [
    "CBOW : [ Continous Bag of Words]\n",
    "-----\n",
    "\n",
    "Predict the target word from  words\n",
    "\n",
    "Uses multiple context words to predict one target word\n",
    "\n",
    "Out of vocabulary issue we will face it will generate output for vocabulary words only for example the words which are not in vocab we pass that will not process \n",
    "and give output as outofvocabulary\n",
    "\n",
    "example :\n",
    "----------\n",
    "\n",
    "\"The cat sat on the mat\"\n",
    "\n",
    "CBOW Example:\n",
    "\n",
    "Context words: [\"The\", \"sat\"]\n",
    "Target word: \"cat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d78ab80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.56314243e-02 -1.90182701e-02 -4.10412991e-04  6.93756482e-03\n",
      " -1.87642663e-03  1.67613048e-02  1.80220641e-02  1.30723128e-02\n",
      " -1.42552785e-03  1.54204927e-02 -1.70695987e-02  6.41235569e-03\n",
      " -9.27880500e-03 -1.01791862e-02  7.17839133e-03  1.07407840e-02\n",
      "  1.55402496e-02 -1.15301441e-02  1.48653621e-02  1.32519286e-02\n",
      " -7.42009981e-03 -1.74906123e-02  1.08772125e-02  1.30185885e-02\n",
      " -1.57406169e-03 -1.34187993e-02 -1.41712418e-02 -4.99332137e-03\n",
      "  1.02863368e-02 -7.33136712e-03 -1.87386647e-02  7.65149994e-03\n",
      "  9.76975355e-03 -1.28588863e-02  2.41649779e-03 -4.14937036e-03\n",
      "  5.24397619e-05 -1.97659265e-02  5.38434321e-03 -9.49859712e-03\n",
      "  2.17847456e-03 -3.15548526e-03  4.39163670e-03 -1.57633983e-02\n",
      " -5.43250563e-03  5.32657886e-03  1.06937252e-02 -4.78297239e-03\n",
      " -1.90195609e-02  9.01283231e-03]\n",
      "[('mat', 0.19009442627429962), ('at', 0.0448918454349041), ('barked', -0.010132141411304474), ('.', -0.014458801597356796), ('chased', -0.02322026900947094), ('sat', -0.04404716566205025), ('log', -0.09487921744585037), ('mouse', -0.12277162820100784), ('The', -0.1551521271467209), ('the', -0.1742183268070221)]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "sentences= [\n",
    "    \"The cat sat on the mat.\",\n",
    "    \"The dog sat on the log.\",\n",
    "    \"The cat chased the mouse.\",\n",
    "    \"The dog barked at the cat.\"\n",
    "]\n",
    "# Tokenize sentences\n",
    "tokenized_sentences = [word_tokenize(sentence) for sentence in sentences]\n",
    "\n",
    "cbow_model = Word2Vec(sentences=tokenized_sentences, vector_size=50, window=2, min_count=1, sg=0)\n",
    "\n",
    "\n",
    "## sg=0 → CBOW model (default) if sg=1 (skipgram)\n",
    "## window=2 → Context window size\n",
    "## vector_size=50 → Embedding size\n",
    " \n",
    "## window represent choose a word [Target word]  so that the 2 words before and after are surrounded  by the selected  target word .\n",
    " \n",
    "print(cbow_model.wv[\"cat\"])  # Get vector representation of \"cat\"\n",
    " \n",
    "print(cbow_model.wv.most_similar(\"cat\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a519ff82",
   "metadata": {},
   "source": [
    " Skip-gram :\n",
    " ----------\n",
    " \n",
    " Predict context words from a target word\n",
    " \n",
    " Uses one target word to predict multiple context words\n",
    " \n",
    " Out of vocabulary issue we will face it will generate output for vocabulary words only for example the words which are not in vocab we pass that will not process \n",
    " and give output as outofvocabulary\n",
    " \n",
    " \n",
    "\n",
    "example :\n",
    "----------\n",
    "\n",
    "\"The cat sat on the mat\" \n",
    " \n",
    " \n",
    " \n",
    " Skip-gram Example:\n",
    " -------------------\n",
    "\n",
    "Target word: \"cat\"\n",
    "Context words: [\"The\", \"sat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bb335dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tokenize sentences\n",
    "tokenized_sentences = [word_tokenize(sentence) for sentence in sentences]\n",
    "\n",
    "cbow_model = Word2Vec(sentences=tokenized_sentences, vector_size=50, window=2, min_count=1, sg=1)\n",
    "\n",
    "cbow_model.save(\"cbow.model\")\n",
    "cbow_model = Word2Vec.load(\"cbow.model\")    \n",
    "\n",
    "\n",
    " ##sg=0 → CBOW model (default) if sg=1 (skipgram)\n",
    " ##window=2 → Context window size\n",
    " ##vector_size=50 → Embedding size\n",
    " \n",
    " \n",
    "##window represent choose a word [Target word]  so that the 2 words before and after are surrounded  by the selected  target word .\n",
    "\n",
    "\n",
    "##Averageword2vec :\n",
    "##Averageword2vec is a simple and effective method for generating word embeddings.\n",
    "##It works by taking the average of the word vectors for all the words in a sentence or document.\n",
    "\n",
    "##Averageword2vec works on taking average of the vector values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82537a1",
   "metadata": {},
   "source": [
    "### Sentence embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a385ce",
   "metadata": {},
   "source": [
    "1. setence transformer\n",
    "2. langchain hugging\n",
    "3. transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1b856f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"I ate dinner.\", \n",
    "       \"We had a three-course meal.\", \n",
    "       \"Brad came to dinner with us.\",\n",
    "       \"He loves fish tacos.\",\n",
    "       \"In the end, we all felt like we ate too much.\",\n",
    "       \"We all agreed; it was a magnificent evening.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c904a8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Downloading torch-2.7.0-cp311-cp311-win_amd64.whl.metadata (29 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-0.31.4-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: Pillow in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from sentence-transformers) (11.2.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from sentence-transformers) (4.13.2)\n",
      "Collecting filelock (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Downloading fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.4.26)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Downloading sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
      "Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "   ---------------------------------------- 0.0/10.4 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.8/10.4 MB 3.7 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.6/10.4 MB 3.8 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 2.4/10.4 MB 3.7 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 3.1/10.4 MB 3.8 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.9/10.4 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.0/10.4 MB 3.8 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 5.8/10.4 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 6.6/10.4 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.3/10.4 MB 3.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.1/10.4 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.9/10.4 MB 3.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.7/10.4 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.4/10.4 MB 3.8 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.31.4-py3-none-any.whl (489 kB)\n",
      "Downloading tokenizers-0.21.1-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.5/2.4 MB 3.4 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.0/2.4 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.6/2.4 MB 3.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.4/2.4 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 3.0 MB/s eta 0:00:00\n",
      "Downloading fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
      "Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Downloading torch-2.7.0-cp311-cp311-win_amd64.whl (212.5 MB)\n",
      "   ---------------------------------------- 0.0/212.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/212.5 MB 3.4 MB/s eta 0:01:04\n",
      "   ---------------------------------------- 1.0/212.5 MB 3.0 MB/s eta 0:01:12\n",
      "   ---------------------------------------- 1.8/212.5 MB 3.0 MB/s eta 0:01:10\n",
      "   ---------------------------------------- 2.4/212.5 MB 3.0 MB/s eta 0:01:09\n",
      "    --------------------------------------- 3.1/212.5 MB 3.1 MB/s eta 0:01:07\n",
      "    --------------------------------------- 3.9/212.5 MB 3.2 MB/s eta 0:01:05\n",
      "    --------------------------------------- 4.7/212.5 MB 3.3 MB/s eta 0:01:04\n",
      "    --------------------------------------- 5.2/212.5 MB 3.3 MB/s eta 0:01:04\n",
      "   - -------------------------------------- 6.0/212.5 MB 3.2 MB/s eta 0:01:04\n",
      "   - -------------------------------------- 6.6/212.5 MB 3.2 MB/s eta 0:01:04\n",
      "   - -------------------------------------- 7.3/212.5 MB 3.2 MB/s eta 0:01:04\n",
      "   - -------------------------------------- 8.1/212.5 MB 3.2 MB/s eta 0:01:04\n",
      "   - -------------------------------------- 8.9/212.5 MB 3.2 MB/s eta 0:01:03\n",
      "   - -------------------------------------- 9.7/212.5 MB 3.3 MB/s eta 0:01:02\n",
      "   - -------------------------------------- 10.5/212.5 MB 3.3 MB/s eta 0:01:01\n",
      "   -- ------------------------------------- 11.3/212.5 MB 3.4 MB/s eta 0:01:00\n",
      "   -- ------------------------------------- 12.1/212.5 MB 3.4 MB/s eta 0:01:00\n",
      "   -- ------------------------------------- 12.8/212.5 MB 3.4 MB/s eta 0:00:59\n",
      "   -- ------------------------------------- 13.6/212.5 MB 3.4 MB/s eta 0:00:58\n",
      "   -- ------------------------------------- 14.4/212.5 MB 3.5 MB/s eta 0:00:58\n",
      "   -- ------------------------------------- 15.2/212.5 MB 3.5 MB/s eta 0:00:57\n",
      "   --- ------------------------------------ 16.0/212.5 MB 3.5 MB/s eta 0:00:57\n",
      "   --- ------------------------------------ 16.8/212.5 MB 3.5 MB/s eta 0:00:56\n",
      "   --- ------------------------------------ 17.6/212.5 MB 3.5 MB/s eta 0:00:56\n",
      "   --- ------------------------------------ 18.6/212.5 MB 3.5 MB/s eta 0:00:55\n",
      "   --- ------------------------------------ 19.4/212.5 MB 3.6 MB/s eta 0:00:55\n",
      "   --- ------------------------------------ 20.2/212.5 MB 3.6 MB/s eta 0:00:54\n",
      "   --- ------------------------------------ 21.0/212.5 MB 3.6 MB/s eta 0:00:54\n",
      "   ---- ----------------------------------- 21.8/212.5 MB 3.6 MB/s eta 0:00:54\n",
      "   ---- ----------------------------------- 22.5/212.5 MB 3.6 MB/s eta 0:00:53\n",
      "   ---- ----------------------------------- 23.3/212.5 MB 3.6 MB/s eta 0:00:53\n",
      "   ---- ----------------------------------- 24.1/212.5 MB 3.6 MB/s eta 0:00:53\n",
      "   ---- ----------------------------------- 24.9/212.5 MB 3.6 MB/s eta 0:00:52\n",
      "   ---- ----------------------------------- 25.7/212.5 MB 3.6 MB/s eta 0:00:52\n",
      "   ---- ----------------------------------- 26.2/212.5 MB 3.6 MB/s eta 0:00:52\n",
      "   ----- ---------------------------------- 27.0/212.5 MB 3.6 MB/s eta 0:00:52\n",
      "   ----- ---------------------------------- 27.5/212.5 MB 3.6 MB/s eta 0:00:52\n",
      "   ----- ---------------------------------- 28.3/212.5 MB 3.6 MB/s eta 0:00:52\n",
      "   ----- ---------------------------------- 28.8/212.5 MB 3.6 MB/s eta 0:00:52\n",
      "   ----- ---------------------------------- 29.4/212.5 MB 3.5 MB/s eta 0:00:52\n",
      "   ----- ---------------------------------- 30.1/212.5 MB 3.5 MB/s eta 0:00:52\n",
      "   ----- ---------------------------------- 30.7/212.5 MB 3.5 MB/s eta 0:00:52\n",
      "   ----- ---------------------------------- 31.2/212.5 MB 3.5 MB/s eta 0:00:52\n",
      "   ----- ---------------------------------- 31.7/212.5 MB 3.5 MB/s eta 0:00:52\n",
      "   ------ --------------------------------- 32.5/212.5 MB 3.5 MB/s eta 0:00:53\n",
      "   ------ --------------------------------- 33.0/212.5 MB 3.4 MB/s eta 0:00:53\n",
      "   ------ --------------------------------- 33.6/212.5 MB 3.4 MB/s eta 0:00:53\n",
      "   ------ --------------------------------- 34.3/212.5 MB 3.4 MB/s eta 0:00:52\n",
      "   ------ --------------------------------- 34.9/212.5 MB 3.4 MB/s eta 0:00:52\n",
      "   ------ --------------------------------- 35.7/212.5 MB 3.4 MB/s eta 0:00:52\n",
      "   ------ --------------------------------- 36.2/212.5 MB 3.4 MB/s eta 0:00:52\n",
      "   ------ --------------------------------- 36.7/212.5 MB 3.4 MB/s eta 0:00:52\n",
      "   ------- -------------------------------- 37.5/212.5 MB 3.4 MB/s eta 0:00:52\n",
      "   ------- -------------------------------- 38.0/212.5 MB 3.4 MB/s eta 0:00:52\n",
      "   ------- -------------------------------- 38.5/212.5 MB 3.4 MB/s eta 0:00:52\n",
      "   ------- -------------------------------- 39.1/212.5 MB 3.4 MB/s eta 0:00:52\n",
      "   ------- -------------------------------- 39.8/212.5 MB 3.4 MB/s eta 0:00:52\n",
      "   ------- -------------------------------- 40.4/212.5 MB 3.4 MB/s eta 0:00:52\n",
      "   ------- -------------------------------- 40.9/212.5 MB 3.4 MB/s eta 0:00:52\n",
      "   ------- -------------------------------- 41.7/212.5 MB 3.3 MB/s eta 0:00:52\n",
      "   ------- -------------------------------- 42.5/212.5 MB 3.3 MB/s eta 0:00:51\n",
      "   -------- ------------------------------- 43.3/212.5 MB 3.4 MB/s eta 0:00:51\n",
      "   -------- ------------------------------- 44.0/212.5 MB 3.4 MB/s eta 0:00:51\n",
      "   -------- ------------------------------- 44.8/212.5 MB 3.4 MB/s eta 0:00:50\n",
      "   -------- ------------------------------- 45.6/212.5 MB 3.4 MB/s eta 0:00:50\n",
      "   -------- ------------------------------- 46.4/212.5 MB 3.4 MB/s eta 0:00:50\n",
      "   -------- ------------------------------- 47.2/212.5 MB 3.4 MB/s eta 0:00:49\n",
      "   --------- ------------------------------ 48.0/212.5 MB 3.4 MB/s eta 0:00:49\n",
      "   --------- ------------------------------ 48.8/212.5 MB 3.4 MB/s eta 0:00:49\n",
      "   --------- ------------------------------ 49.5/212.5 MB 3.4 MB/s eta 0:00:48\n",
      "   --------- ------------------------------ 50.3/212.5 MB 3.4 MB/s eta 0:00:48\n",
      "   --------- ------------------------------ 51.1/212.5 MB 3.4 MB/s eta 0:00:48\n",
      "   --------- ------------------------------ 51.9/212.5 MB 3.4 MB/s eta 0:00:47\n",
      "   --------- ------------------------------ 52.7/212.5 MB 3.4 MB/s eta 0:00:47\n",
      "   ---------- ----------------------------- 53.5/212.5 MB 3.4 MB/s eta 0:00:47\n",
      "   ---------- ----------------------------- 54.3/212.5 MB 3.4 MB/s eta 0:00:46\n",
      "   ---------- ----------------------------- 55.3/212.5 MB 3.5 MB/s eta 0:00:46\n",
      "   ---------- ----------------------------- 55.8/212.5 MB 3.5 MB/s eta 0:00:46\n",
      "   ---------- ----------------------------- 56.4/212.5 MB 3.5 MB/s eta 0:00:46\n",
      "   ---------- ----------------------------- 57.1/212.5 MB 3.4 MB/s eta 0:00:46\n",
      "   ---------- ----------------------------- 57.7/212.5 MB 3.4 MB/s eta 0:00:46\n",
      "   ---------- ----------------------------- 58.2/212.5 MB 3.4 MB/s eta 0:00:45\n",
      "   ----------- ---------------------------- 59.0/212.5 MB 3.4 MB/s eta 0:00:45\n",
      "   ----------- ---------------------------- 59.5/212.5 MB 3.4 MB/s eta 0:00:45\n",
      "   ----------- ---------------------------- 60.0/212.5 MB 3.4 MB/s eta 0:00:45\n",
      "   ----------- ---------------------------- 60.8/212.5 MB 3.4 MB/s eta 0:00:45\n",
      "   ----------- ---------------------------- 61.3/212.5 MB 3.4 MB/s eta 0:00:45\n",
      "   ----------- ---------------------------- 61.9/212.5 MB 3.4 MB/s eta 0:00:45\n",
      "   ----------- ---------------------------- 62.7/212.5 MB 3.4 MB/s eta 0:00:45\n",
      "   ----------- ---------------------------- 63.2/212.5 MB 3.4 MB/s eta 0:00:45\n",
      "   ----------- ---------------------------- 63.7/212.5 MB 3.4 MB/s eta 0:00:45\n",
      "   ------------ --------------------------- 64.2/212.5 MB 3.4 MB/s eta 0:00:44\n",
      "   ------------ --------------------------- 65.0/212.5 MB 3.4 MB/s eta 0:00:44\n",
      "   ------------ --------------------------- 65.5/212.5 MB 3.4 MB/s eta 0:00:44\n",
      "   ------------ --------------------------- 66.1/212.5 MB 3.4 MB/s eta 0:00:44\n",
      "   ------------ --------------------------- 66.8/212.5 MB 3.4 MB/s eta 0:00:44\n",
      "   ------------ --------------------------- 67.4/212.5 MB 3.4 MB/s eta 0:00:44\n",
      "   ------------ --------------------------- 67.9/212.5 MB 3.3 MB/s eta 0:00:44\n",
      "   ------------ --------------------------- 68.7/212.5 MB 3.3 MB/s eta 0:00:44\n",
      "   ------------- -------------------------- 69.2/212.5 MB 3.3 MB/s eta 0:00:43\n",
      "   ------------- -------------------------- 69.7/212.5 MB 3.3 MB/s eta 0:00:43\n",
      "   ------------- -------------------------- 70.5/212.5 MB 3.3 MB/s eta 0:00:43\n",
      "   ------------- -------------------------- 71.0/212.5 MB 3.3 MB/s eta 0:00:43\n",
      "   ------------- -------------------------- 71.6/212.5 MB 3.3 MB/s eta 0:00:43\n",
      "   ------------- -------------------------- 72.1/212.5 MB 3.3 MB/s eta 0:00:43\n",
      "   ------------- -------------------------- 72.9/212.5 MB 3.3 MB/s eta 0:00:43\n",
      "   ------------- -------------------------- 73.4/212.5 MB 3.3 MB/s eta 0:00:42\n",
      "   ------------- -------------------------- 74.2/212.5 MB 3.3 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 74.7/212.5 MB 3.3 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 75.2/212.5 MB 3.3 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 75.8/212.5 MB 3.3 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 76.5/212.5 MB 3.3 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 77.1/212.5 MB 3.3 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 77.6/212.5 MB 3.3 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 78.4/212.5 MB 3.3 MB/s eta 0:00:41\n",
      "   -------------- ------------------------- 78.9/212.5 MB 3.3 MB/s eta 0:00:41\n",
      "   -------------- ------------------------- 79.4/212.5 MB 3.3 MB/s eta 0:00:41\n",
      "   --------------- ------------------------ 80.0/212.5 MB 3.3 MB/s eta 0:00:41\n",
      "   --------------- ------------------------ 80.7/212.5 MB 3.3 MB/s eta 0:00:41\n",
      "   --------------- ------------------------ 81.3/212.5 MB 3.3 MB/s eta 0:00:41\n",
      "   --------------- ------------------------ 81.8/212.5 MB 3.3 MB/s eta 0:00:41\n",
      "   --------------- ------------------------ 82.6/212.5 MB 3.3 MB/s eta 0:00:40\n",
      "   --------------- ------------------------ 83.1/212.5 MB 3.3 MB/s eta 0:00:40\n",
      "   --------------- ------------------------ 83.6/212.5 MB 3.3 MB/s eta 0:00:40\n",
      "   --------------- ------------------------ 84.1/212.5 MB 3.3 MB/s eta 0:00:40\n",
      "   --------------- ------------------------ 84.9/212.5 MB 3.3 MB/s eta 0:00:40\n",
      "   ---------------- ----------------------- 85.5/212.5 MB 3.2 MB/s eta 0:00:40\n",
      "   ---------------- ----------------------- 86.0/212.5 MB 3.2 MB/s eta 0:00:40\n",
      "   ---------------- ----------------------- 86.8/212.5 MB 3.2 MB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 87.3/212.5 MB 3.2 MB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 87.8/212.5 MB 3.2 MB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 88.6/212.5 MB 3.2 MB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 89.1/212.5 MB 3.2 MB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 89.7/212.5 MB 3.2 MB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 90.2/212.5 MB 3.2 MB/s eta 0:00:38\n",
      "   ----------------- ---------------------- 91.0/212.5 MB 3.2 MB/s eta 0:00:38\n",
      "   ----------------- ---------------------- 91.5/212.5 MB 3.2 MB/s eta 0:00:38\n",
      "   ----------------- ---------------------- 92.0/212.5 MB 3.2 MB/s eta 0:00:38\n",
      "   ----------------- ---------------------- 92.8/212.5 MB 3.2 MB/s eta 0:00:38\n",
      "   ----------------- ---------------------- 93.3/212.5 MB 3.2 MB/s eta 0:00:38\n",
      "   ----------------- ---------------------- 93.8/212.5 MB 3.2 MB/s eta 0:00:37\n",
      "   ----------------- ---------------------- 94.6/212.5 MB 3.2 MB/s eta 0:00:37\n",
      "   ----------------- ---------------------- 95.2/212.5 MB 3.2 MB/s eta 0:00:37\n",
      "   ------------------ --------------------- 95.7/212.5 MB 3.2 MB/s eta 0:00:37\n",
      "   ------------------ --------------------- 96.5/212.5 MB 3.2 MB/s eta 0:00:37\n",
      "   ------------------ --------------------- 97.0/212.5 MB 3.2 MB/s eta 0:00:36\n",
      "   ------------------ --------------------- 97.8/212.5 MB 3.2 MB/s eta 0:00:36\n",
      "   ------------------ --------------------- 98.3/212.5 MB 3.2 MB/s eta 0:00:36\n",
      "   ------------------ --------------------- 99.1/212.5 MB 3.2 MB/s eta 0:00:36\n",
      "   ------------------ --------------------- 99.6/212.5 MB 3.2 MB/s eta 0:00:36\n",
      "   ------------------ --------------------- 100.1/212.5 MB 3.2 MB/s eta 0:00:36\n",
      "   ------------------ --------------------- 100.9/212.5 MB 3.2 MB/s eta 0:00:35\n",
      "   ------------------- -------------------- 101.4/212.5 MB 3.2 MB/s eta 0:00:35\n",
      "   ------------------- -------------------- 102.0/212.5 MB 3.2 MB/s eta 0:00:35\n",
      "   ------------------- -------------------- 102.8/212.5 MB 3.2 MB/s eta 0:00:35\n",
      "   ------------------- -------------------- 103.3/212.5 MB 3.2 MB/s eta 0:00:35\n",
      "   ------------------- -------------------- 103.8/212.5 MB 3.2 MB/s eta 0:00:35\n",
      "   ------------------- -------------------- 104.3/212.5 MB 3.2 MB/s eta 0:00:34\n",
      "   ------------------- -------------------- 105.1/212.5 MB 3.2 MB/s eta 0:00:34\n",
      "   ------------------- -------------------- 105.6/212.5 MB 3.2 MB/s eta 0:00:34\n",
      "   ------------------- -------------------- 106.2/212.5 MB 3.2 MB/s eta 0:00:34\n",
      "   -------------------- ------------------- 106.7/212.5 MB 3.2 MB/s eta 0:00:34\n",
      "   -------------------- ------------------- 107.5/212.5 MB 3.1 MB/s eta 0:00:34\n",
      "   -------------------- ------------------- 108.0/212.5 MB 3.1 MB/s eta 0:00:34\n",
      "   -------------------- ------------------- 108.5/212.5 MB 3.1 MB/s eta 0:00:34\n",
      "   -------------------- ------------------- 109.3/212.5 MB 3.1 MB/s eta 0:00:33\n",
      "   -------------------- ------------------- 109.8/212.5 MB 3.1 MB/s eta 0:00:33\n",
      "   -------------------- ------------------- 110.6/212.5 MB 3.1 MB/s eta 0:00:33\n",
      "   -------------------- ------------------- 111.1/212.5 MB 3.1 MB/s eta 0:00:33\n",
      "   --------------------- ------------------ 111.7/212.5 MB 3.1 MB/s eta 0:00:33\n",
      "   --------------------- ------------------ 112.5/212.5 MB 3.1 MB/s eta 0:00:33\n",
      "   --------------------- ------------------ 113.0/212.5 MB 3.1 MB/s eta 0:00:33\n",
      "   --------------------- ------------------ 113.5/212.5 MB 3.1 MB/s eta 0:00:33\n",
      "   --------------------- ------------------ 114.3/212.5 MB 3.1 MB/s eta 0:00:32\n",
      "   --------------------- ------------------ 114.8/212.5 MB 3.1 MB/s eta 0:00:32\n",
      "   --------------------- ------------------ 115.3/212.5 MB 3.1 MB/s eta 0:00:32\n",
      "   --------------------- ------------------ 115.9/212.5 MB 3.1 MB/s eta 0:00:32\n",
      "   --------------------- ------------------ 116.7/212.5 MB 3.1 MB/s eta 0:00:32\n",
      "   ---------------------- ----------------- 117.2/212.5 MB 3.0 MB/s eta 0:00:32\n",
      "   ---------------------- ----------------- 117.7/212.5 MB 3.0 MB/s eta 0:00:32\n",
      "   ---------------------- ----------------- 118.5/212.5 MB 3.0 MB/s eta 0:00:31\n",
      "   ---------------------- ----------------- 119.0/212.5 MB 3.0 MB/s eta 0:00:31\n",
      "   ---------------------- ----------------- 119.5/212.5 MB 3.0 MB/s eta 0:00:31\n",
      "   ---------------------- ----------------- 120.3/212.5 MB 3.0 MB/s eta 0:00:31\n",
      "   ---------------------- ----------------- 120.8/212.5 MB 3.0 MB/s eta 0:00:31\n",
      "   ---------------------- ----------------- 121.4/212.5 MB 3.0 MB/s eta 0:00:30\n",
      "   ---------------------- ----------------- 122.2/212.5 MB 3.0 MB/s eta 0:00:30\n",
      "   ----------------------- ---------------- 122.7/212.5 MB 3.0 MB/s eta 0:00:30\n",
      "   ----------------------- ---------------- 123.2/212.5 MB 3.0 MB/s eta 0:00:30\n",
      "   ----------------------- ---------------- 123.7/212.5 MB 3.0 MB/s eta 0:00:30\n",
      "   ----------------------- ---------------- 124.5/212.5 MB 3.0 MB/s eta 0:00:29\n",
      "   ----------------------- ---------------- 125.0/212.5 MB 3.0 MB/s eta 0:00:29\n",
      "   ----------------------- ---------------- 125.8/212.5 MB 3.0 MB/s eta 0:00:29\n",
      "   ----------------------- ---------------- 126.4/212.5 MB 3.0 MB/s eta 0:00:29\n",
      "   ----------------------- ---------------- 127.1/212.5 MB 3.0 MB/s eta 0:00:29\n",
      "   ------------------------ --------------- 127.7/212.5 MB 3.0 MB/s eta 0:00:28\n",
      "   ------------------------ --------------- 128.2/212.5 MB 3.0 MB/s eta 0:00:28\n",
      "   ------------------------ --------------- 129.0/212.5 MB 3.0 MB/s eta 0:00:28\n",
      "   ------------------------ --------------- 129.5/212.5 MB 3.0 MB/s eta 0:00:28\n",
      "   ------------------------ --------------- 130.0/212.5 MB 3.0 MB/s eta 0:00:28\n",
      "   ------------------------ --------------- 130.8/212.5 MB 3.0 MB/s eta 0:00:27\n",
      "   ------------------------ --------------- 131.3/212.5 MB 3.0 MB/s eta 0:00:27\n",
      "   ------------------------ --------------- 131.9/212.5 MB 3.0 MB/s eta 0:00:27\n",
      "   ------------------------ --------------- 132.6/212.5 MB 3.0 MB/s eta 0:00:27\n",
      "   ------------------------- -------------- 133.2/212.5 MB 3.0 MB/s eta 0:00:27\n",
      "   ------------------------- -------------- 133.7/212.5 MB 3.0 MB/s eta 0:00:26\n",
      "   ------------------------- -------------- 134.5/212.5 MB 3.0 MB/s eta 0:00:26\n",
      "   ------------------------- -------------- 135.0/212.5 MB 3.0 MB/s eta 0:00:26\n",
      "   ------------------------- -------------- 135.8/212.5 MB 3.0 MB/s eta 0:00:26\n",
      "   ------------------------- -------------- 136.3/212.5 MB 3.0 MB/s eta 0:00:26\n",
      "   ------------------------- -------------- 137.1/212.5 MB 3.0 MB/s eta 0:00:25\n",
      "   ------------------------- -------------- 137.9/212.5 MB 3.0 MB/s eta 0:00:25\n",
      "   -------------------------- ------------- 138.7/212.5 MB 3.0 MB/s eta 0:00:25\n",
      "   -------------------------- ------------- 139.5/212.5 MB 3.0 MB/s eta 0:00:25\n",
      "   -------------------------- ------------- 140.2/212.5 MB 3.0 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 141.0/212.5 MB 3.0 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 141.8/212.5 MB 3.0 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 142.6/212.5 MB 3.0 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 143.4/212.5 MB 3.0 MB/s eta 0:00:23\n",
      "   --------------------------- ------------ 144.2/212.5 MB 3.0 MB/s eta 0:00:23\n",
      "   --------------------------- ------------ 145.2/212.5 MB 3.0 MB/s eta 0:00:23\n",
      "   --------------------------- ------------ 146.0/212.5 MB 3.0 MB/s eta 0:00:23\n",
      "   --------------------------- ------------ 146.8/212.5 MB 3.0 MB/s eta 0:00:22\n",
      "   --------------------------- ------------ 147.6/212.5 MB 3.0 MB/s eta 0:00:22\n",
      "   --------------------------- ------------ 148.4/212.5 MB 3.0 MB/s eta 0:00:22\n",
      "   ---------------------------- ----------- 149.2/212.5 MB 3.0 MB/s eta 0:00:21\n",
      "   ---------------------------- ----------- 149.9/212.5 MB 3.0 MB/s eta 0:00:21\n",
      "   ---------------------------- ----------- 150.7/212.5 MB 3.1 MB/s eta 0:00:21\n",
      "   ---------------------------- ----------- 151.5/212.5 MB 3.1 MB/s eta 0:00:20\n",
      "   ---------------------------- ----------- 152.3/212.5 MB 3.1 MB/s eta 0:00:20\n",
      "   ---------------------------- ----------- 153.1/212.5 MB 3.1 MB/s eta 0:00:20\n",
      "   ---------------------------- ----------- 153.9/212.5 MB 3.1 MB/s eta 0:00:20\n",
      "   ----------------------------- ---------- 154.7/212.5 MB 3.1 MB/s eta 0:00:19\n",
      "   ----------------------------- ---------- 155.5/212.5 MB 3.1 MB/s eta 0:00:19\n",
      "   ----------------------------- ---------- 156.2/212.5 MB 3.1 MB/s eta 0:00:19\n",
      "   ----------------------------- ---------- 157.3/212.5 MB 3.1 MB/s eta 0:00:18\n",
      "   ----------------------------- ---------- 158.1/212.5 MB 3.1 MB/s eta 0:00:18\n",
      "   ----------------------------- ---------- 158.9/212.5 MB 3.1 MB/s eta 0:00:18\n",
      "   ------------------------------ --------- 159.6/212.5 MB 3.1 MB/s eta 0:00:17\n",
      "   ------------------------------ --------- 160.4/212.5 MB 3.1 MB/s eta 0:00:17\n",
      "   ------------------------------ --------- 161.2/212.5 MB 3.1 MB/s eta 0:00:17\n",
      "   ------------------------------ --------- 162.0/212.5 MB 3.1 MB/s eta 0:00:17\n",
      "   ------------------------------ --------- 162.8/212.5 MB 3.2 MB/s eta 0:00:16\n",
      "   ------------------------------ --------- 163.6/212.5 MB 3.2 MB/s eta 0:00:16\n",
      "   ------------------------------ --------- 164.4/212.5 MB 3.2 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 165.2/212.5 MB 3.2 MB/s eta 0:00:15\n",
      "   ------------------------------- -------- 165.9/212.5 MB 3.2 MB/s eta 0:00:15\n",
      "   ------------------------------- -------- 166.7/212.5 MB 3.2 MB/s eta 0:00:15\n",
      "   ------------------------------- -------- 167.5/212.5 MB 3.2 MB/s eta 0:00:15\n",
      "   ------------------------------- -------- 168.3/212.5 MB 3.2 MB/s eta 0:00:14\n",
      "   ------------------------------- -------- 169.1/212.5 MB 3.2 MB/s eta 0:00:14\n",
      "   ------------------------------- -------- 169.9/212.5 MB 3.2 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 170.7/212.5 MB 3.2 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 171.4/212.5 MB 3.2 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 172.2/212.5 MB 3.2 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 173.0/212.5 MB 3.2 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 173.8/212.5 MB 3.2 MB/s eta 0:00:12\n",
      "   -------------------------------- ------- 174.6/212.5 MB 3.2 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 175.4/212.5 MB 3.3 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 176.2/212.5 MB 3.3 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 177.2/212.5 MB 3.3 MB/s eta 0:00:11\n",
      "   --------------------------------- ------ 178.0/212.5 MB 3.3 MB/s eta 0:00:11\n",
      "   --------------------------------- ------ 178.8/212.5 MB 3.3 MB/s eta 0:00:11\n",
      "   --------------------------------- ------ 179.6/212.5 MB 3.3 MB/s eta 0:00:11\n",
      "   --------------------------------- ------ 180.4/212.5 MB 3.3 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 181.1/212.5 MB 3.3 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 181.9/212.5 MB 3.3 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 182.7/212.5 MB 3.3 MB/s eta 0:00:09\n",
      "   ---------------------------------- ----- 183.5/212.5 MB 3.3 MB/s eta 0:00:09\n",
      "   ---------------------------------- ----- 184.3/212.5 MB 3.3 MB/s eta 0:00:09\n",
      "   ---------------------------------- ----- 185.1/212.5 MB 3.3 MB/s eta 0:00:09\n",
      "   ---------------------------------- ----- 185.9/212.5 MB 3.3 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 186.6/212.5 MB 3.3 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 187.4/212.5 MB 3.4 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 188.2/212.5 MB 3.4 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 189.3/212.5 MB 3.4 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 190.1/212.5 MB 3.4 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 190.8/212.5 MB 3.4 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 191.6/212.5 MB 3.4 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 192.4/212.5 MB 3.4 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 193.2/212.5 MB 3.4 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 194.0/212.5 MB 3.4 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 195.0/212.5 MB 3.4 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 195.8/212.5 MB 3.4 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 196.6/212.5 MB 3.4 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 197.4/212.5 MB 3.4 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 198.2/212.5 MB 3.4 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 199.0/212.5 MB 3.4 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 199.8/212.5 MB 3.5 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 200.5/212.5 MB 3.5 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 201.3/212.5 MB 3.5 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 202.1/212.5 MB 3.5 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 202.9/212.5 MB 3.5 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 203.9/212.5 MB 3.5 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 204.7/212.5 MB 3.5 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 205.5/212.5 MB 3.5 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 206.3/212.5 MB 3.5 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 207.1/212.5 MB 3.5 MB/s eta 0:00:02\n",
      "   ---------------------------------------  207.9/212.5 MB 3.5 MB/s eta 0:00:02\n",
      "   ---------------------------------------  208.7/212.5 MB 3.5 MB/s eta 0:00:02\n",
      "   ---------------------------------------  209.5/212.5 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  210.2/212.5 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  211.0/212.5 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  211.8/212.5 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  212.3/212.5 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  212.3/212.5 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  212.3/212.5 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  212.3/212.5 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  212.3/212.5 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  212.3/212.5 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  212.3/212.5 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  212.3/212.5 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 212.5/212.5 MB 3.4 MB/s eta 0:00:00\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.8/6.3 MB 6.7 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 1.8/6.3 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 2.6/6.3 MB 4.3 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 3.7/6.3 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 4.5/6.3 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 5.0/6.3 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.8/6.3 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 3.9 MB/s eta 0:00:00\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 536.2/536.2 kB 2.9 MB/s eta 0:00:00\n",
      "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 0.8/1.7 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 3.7 MB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, sympy, safetensors, networkx, fsspec, filelock, torch, huggingface-hub, tokenizers, transformers, sentence-transformers\n",
      "\n",
      "   ----------------------------------------  0/11 [mpmath]\n",
      "   ----------------------------------------  0/11 [mpmath]\n",
      "   ----------------------------------------  0/11 [mpmath]\n",
      "   ----------------------------------------  0/11 [mpmath]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   --- ------------------------------------  1/11 [sympy]\n",
      "   ---------- -----------------------------  3/11 [networkx]\n",
      "   ---------- -----------------------------  3/11 [networkx]\n",
      "   ---------- -----------------------------  3/11 [networkx]\n",
      "   ---------- -----------------------------  3/11 [networkx]\n",
      "   ---------- -----------------------------  3/11 [networkx]\n",
      "   ---------- -----------------------------  3/11 [networkx]\n",
      "   ---------- -----------------------------  3/11 [networkx]\n",
      "   ---------- -----------------------------  3/11 [networkx]\n",
      "   ---------- -----------------------------  3/11 [networkx]\n",
      "   ---------- -----------------------------  3/11 [networkx]\n",
      "   ---------- -----------------------------  3/11 [networkx]\n",
      "   ---------- -----------------------------  3/11 [networkx]\n",
      "   ---------- -----------------------------  3/11 [networkx]\n",
      "   -------------- -------------------------  4/11 [fsspec]\n",
      "   ------------------ ---------------------  5/11 [filelock]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   --------------------- ------------------  6/11 [torch]\n",
      "   ------------------------- --------------  7/11 [huggingface-hub]\n",
      "   ------------------------- --------------  7/11 [huggingface-hub]\n",
      "   ----------------------------- ----------  8/11 [tokenizers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   -------------------------------- -------  9/11 [transformers]\n",
      "   ------------------------------------ --- 10/11 [sentence-transformers]\n",
      "   ------------------------------------ --- 10/11 [sentence-transformers]\n",
      "   ---------------------------------------- 11/11 [sentence-transformers]\n",
      "\n",
      "Successfully installed filelock-3.18.0 fsspec-2025.3.2 huggingface-hub-0.31.4 mpmath-1.3.0 networkx-3.4.2 safetensors-0.5.3 sentence-transformers-4.1.0 sympy-1.14.0 tokenizers-0.21.1 torch-2.7.0 transformers-4.51.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chand\\anaconda3\\envs\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "35be74ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chand\\anaconda3\\envs\\env\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\chand\\.cache\\huggingface\\hub\\models--sentence-transformers--all-mpnet-base-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e6d34fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I ate dinner.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9a40ef6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.58597678e-02,  4.59826551e-02, -1.46349585e-02, -4.85908687e-02,\n",
       "       -3.60319996e-03,  3.17664109e-02, -3.27771641e-02,  2.11895313e-02,\n",
       "        1.07366042e-02,  2.50182096e-02,  1.58237889e-02,  1.24069359e-02,\n",
       "        1.62089840e-02, -1.30434325e-02,  4.58446629e-02,  4.40269858e-02,\n",
       "        4.57802415e-02, -4.32259543e-03,  1.87806357e-02,  5.22195548e-03,\n",
       "       -1.86415315e-02, -7.11804302e-03,  3.01359687e-02,  1.70695819e-02,\n",
       "       -1.53764402e-02,  3.34172398e-02, -6.55884482e-03,  1.58591792e-02,\n",
       "        1.37038892e-02, -2.02767160e-02,  3.26631889e-02,  5.48361661e-03,\n",
       "       -3.53351422e-02, -1.06665209e-01,  1.85711565e-06,  3.66638750e-02,\n",
       "       -1.71336550e-02,  3.34468447e-02, -6.43022060e-02,  6.90796226e-02,\n",
       "        2.50845030e-02,  2.89430898e-02, -8.98415409e-03, -1.84546430e-02,\n",
       "        2.81152073e-02, -2.34797206e-02,  1.21612307e-02,  6.25151247e-02,\n",
       "       -8.58704001e-02, -1.84621708e-03,  7.95865990e-03, -8.42522830e-02,\n",
       "       -2.26104409e-02,  7.21652061e-03,  2.59821699e-03,  1.28878271e-02,\n",
       "        1.31184794e-02, -1.40280984e-02,  1.85120739e-02, -1.50230899e-02,\n",
       "        1.10535119e-02,  1.02814063e-02,  9.40545183e-03,  4.65564765e-02,\n",
       "        4.04661894e-02,  2.98436787e-02,  2.30588410e-02, -9.56835970e-03,\n",
       "       -6.97248708e-03, -3.25503200e-03,  5.75622218e-03, -2.86775529e-02,\n",
       "        4.26814007e-03,  7.02844467e-03, -3.25724781e-02, -8.53253156e-02,\n",
       "       -1.82672695e-03, -1.19525101e-02,  3.00709940e-02,  1.06549896e-02,\n",
       "        6.04647063e-02,  3.74978594e-02,  1.93042643e-02, -6.08700840e-03,\n",
       "        1.31480191e-02,  3.11517809e-02,  5.17085269e-02, -2.14071665e-02,\n",
       "       -4.98082191e-02,  1.41700329e-02, -1.54425274e-04,  5.96486917e-03,\n",
       "        3.77815068e-02,  1.88497826e-02,  1.82054620e-02, -7.94760883e-03,\n",
       "        7.14984164e-03,  1.79809798e-02,  2.96121296e-02,  8.90167523e-03,\n",
       "       -4.28315662e-02,  1.40012670e-02, -6.78029209e-02, -1.18278340e-02,\n",
       "       -4.25322205e-02,  6.77722618e-02, -5.84640466e-02, -4.41408381e-02,\n",
       "       -1.05593123e-01,  8.63258727e-04, -3.74521054e-02, -2.02775300e-02,\n",
       "        4.42328192e-02,  6.30339012e-02,  3.72218550e-03, -7.10149342e-03,\n",
       "        5.87496832e-02, -1.77735630e-02,  2.42016111e-02, -4.91736224e-04,\n",
       "       -4.19575945e-02,  1.19406171e-03,  1.03313848e-02,  6.10738471e-02,\n",
       "       -4.37645540e-02,  6.50699362e-02, -4.20008525e-02,  2.29213573e-02,\n",
       "        1.31198103e-02, -8.17685053e-02, -9.69565287e-03, -1.48490807e-02,\n",
       "       -3.15134302e-02, -5.08222282e-02,  2.85881851e-02,  8.88475962e-03,\n",
       "       -5.03060892e-02,  1.42504666e-02,  5.76837324e-02, -5.51900901e-02,\n",
       "       -2.69924887e-02, -5.75252883e-02,  4.46648002e-02,  4.45759948e-03,\n",
       "        2.51233373e-02,  1.85715817e-02,  1.15396148e-02,  2.88802441e-02,\n",
       "        2.38203220e-02,  2.48824824e-02, -2.97696795e-02,  7.64077157e-03,\n",
       "       -6.90763234e-04,  2.48531718e-02, -2.62040994e-03, -1.18771903e-02,\n",
       "        5.20075150e-02,  1.01942499e-03,  4.16889191e-02,  4.28791204e-03,\n",
       "        7.62179028e-03,  1.45216612e-02, -3.54440510e-02,  1.07835764e-02,\n",
       "       -1.93941954e-03, -3.40355618e-04, -1.08395191e-03,  2.25106571e-02,\n",
       "       -2.68089641e-02, -4.96655293e-02, -2.46529579e-02,  1.38710858e-02,\n",
       "       -1.18675353e-02,  4.91955280e-02,  8.10240209e-02,  3.23882885e-02,\n",
       "       -6.89732432e-02,  7.07735568e-02, -1.71234440e-02, -5.31037077e-02,\n",
       "        6.90852350e-04,  8.25337991e-02, -5.41862193e-03, -1.21965818e-02,\n",
       "       -2.57876739e-02,  1.29037425e-02,  3.97710279e-02,  1.16599910e-02,\n",
       "       -4.71499525e-02, -1.55416585e-03,  2.14158576e-02,  1.21262679e-02,\n",
       "        1.17830768e-01,  2.07086727e-02,  2.16069147e-02, -1.81928612e-02,\n",
       "       -2.43831556e-02, -1.84702296e-02,  2.88840458e-02, -5.97509444e-02,\n",
       "        2.14757733e-02,  3.20827439e-02,  7.62479007e-02,  3.80869731e-02,\n",
       "        3.45983095e-02, -4.29250859e-02, -2.74348781e-02, -2.71050702e-03,\n",
       "        4.90295812e-02, -4.41903807e-03, -2.57232115e-02, -1.32094501e-02,\n",
       "        2.61985101e-02,  1.94365382e-02, -4.45672162e-02,  3.29500576e-03,\n",
       "        1.72698852e-02, -1.32996598e-02,  1.42141934e-02,  5.69111891e-02,\n",
       "       -3.62573862e-02, -1.41077479e-02, -2.02276316e-02,  1.82423908e-02,\n",
       "        5.26576415e-02, -1.01200454e-02,  1.54184196e-02, -1.43442070e-02,\n",
       "       -4.23691645e-02, -4.37279418e-02,  9.64315329e-03,  4.04550172e-02,\n",
       "       -1.14073372e-02,  4.93268184e-02, -9.71715618e-03,  5.46151847e-02,\n",
       "        2.97969207e-02, -5.09547554e-02, -3.63159105e-02, -2.95957830e-02,\n",
       "        5.14643118e-02,  2.31801227e-04, -1.07930563e-02, -3.80907627e-03,\n",
       "        2.90464684e-02, -3.24545577e-02, -2.88730040e-02, -4.38747369e-02,\n",
       "       -5.69990501e-02,  2.82499492e-02,  1.30839162e-02, -2.26316247e-02,\n",
       "       -1.82015263e-02, -2.35346276e-02,  1.76654756e-02, -6.19094670e-02,\n",
       "       -1.76499989e-02, -6.84201531e-03,  1.26651572e-02,  9.16165262e-02,\n",
       "        2.64643859e-02, -3.54639702e-02, -2.48465575e-02,  1.97095443e-02,\n",
       "        8.28408543e-03, -4.95948084e-02,  7.40016671e-03, -5.44814356e-02,\n",
       "        4.28938278e-04, -4.23534140e-02,  5.82957128e-03,  3.07193268e-02,\n",
       "       -1.48841031e-02,  3.16152871e-02, -2.68768556e-02, -9.47801047e-04,\n",
       "        1.25227273e-02, -3.57248373e-02, -1.67506281e-02,  1.37194032e-02,\n",
       "        4.24945867e-03,  5.27573265e-02, -9.80025064e-03, -1.08689638e-02,\n",
       "       -1.24133211e-02,  1.91955604e-02, -3.58564779e-02, -9.97185409e-02,\n",
       "        6.43670186e-02, -3.15426588e-02, -2.69128587e-02, -1.35610206e-02,\n",
       "       -9.34542529e-03, -4.93993275e-02,  4.51085530e-02,  6.02009241e-03,\n",
       "       -6.92176912e-03, -1.54350670e-02,  4.53561209e-02, -5.89580042e-03,\n",
       "        1.05213048e-02, -3.40148527e-03,  1.51837394e-02,  8.79015028e-03,\n",
       "        3.56569100e-04,  2.25682892e-02, -6.91524968e-02, -7.66746104e-02,\n",
       "        1.29864346e-02,  5.04967310e-02,  1.50756370e-02,  2.16731112e-02,\n",
       "       -2.95116641e-02, -6.00571968e-02, -2.29868032e-02, -1.04990276e-02,\n",
       "       -6.96851360e-03,  3.18047628e-02,  5.66541450e-03,  1.75470151e-02,\n",
       "        2.71979980e-02,  3.44706289e-02,  1.88785959e-02, -3.29418182e-02,\n",
       "        9.57655441e-03,  5.50614856e-03, -1.52026741e-02,  2.08035926e-03,\n",
       "        5.36028631e-02, -6.70924131e-03,  1.05932755e-02, -1.78985335e-02,\n",
       "        1.10722501e-02, -5.40628918e-02, -2.52347216e-02, -3.76276374e-02,\n",
       "       -1.26187876e-02,  4.19355445e-02, -1.90690849e-02, -1.96487475e-02,\n",
       "        3.94429266e-02,  4.67757434e-02, -8.10251012e-03, -8.41667205e-02,\n",
       "       -9.59752575e-02,  1.51462685e-02, -8.22182512e-04,  2.00969800e-02,\n",
       "       -8.18412304e-02, -3.58317494e-02, -6.77416846e-02, -5.26525453e-02,\n",
       "        2.46512461e-02, -1.33464606e-02, -3.42225134e-02,  2.58780736e-02,\n",
       "       -2.66649220e-02,  6.51573166e-02, -1.12581463e-03, -1.95963625e-02,\n",
       "        1.83231290e-02,  3.94513123e-02,  2.86751539e-02,  2.81555708e-02,\n",
       "        1.75660849e-02,  1.72639228e-02,  3.68377827e-02, -2.39951555e-02,\n",
       "       -5.43987611e-03, -2.74543911e-02, -3.26096304e-02,  7.32505415e-03,\n",
       "       -1.17906565e-02,  1.44643942e-02, -3.15678492e-02,  5.94952069e-02,\n",
       "        1.69740841e-02,  2.20812764e-03,  3.95897888e-02, -1.69411264e-02,\n",
       "        3.56196612e-02, -9.37269256e-02, -2.98592374e-02,  3.93665358e-02,\n",
       "       -1.38473231e-02, -7.10827783e-02,  1.55497659e-02, -3.29901086e-04,\n",
       "       -7.28902742e-02, -2.15077307e-02,  1.86752751e-02, -3.46289314e-02,\n",
       "        4.25321199e-02,  1.73439439e-02,  4.00773175e-02,  4.68754694e-02,\n",
       "       -4.55647446e-02,  4.01489697e-02,  1.42339617e-02,  4.65468653e-02,\n",
       "       -2.28002435e-03,  3.16909328e-02,  6.24307990e-02,  4.86361980e-02,\n",
       "        3.26480232e-02,  1.79937016e-02, -4.62855585e-02,  2.25095022e-02,\n",
       "        7.00979866e-03, -3.31501774e-02,  1.46785928e-02,  9.74486489e-03,\n",
       "        3.75680532e-03, -3.06933746e-03,  5.25607057e-02, -4.82424628e-03,\n",
       "       -1.55553641e-02, -1.32089853e-02,  1.22427754e-02, -5.44230156e-02,\n",
       "       -7.97448531e-02,  1.97087303e-02,  3.37717272e-02, -3.82510433e-03,\n",
       "       -8.37580860e-02,  4.10214290e-02,  2.94716991e-02,  4.52255225e-03,\n",
       "        1.07993530e-02, -2.96981353e-02,  5.67335710e-02, -1.21642258e-02,\n",
       "       -8.40554858e-05, -3.02090626e-02,  7.73441885e-03, -3.26075964e-02,\n",
       "        4.02261950e-02, -1.28654763e-02, -7.96076655e-02, -1.55287106e-02,\n",
       "        1.37523026e-03, -4.16691825e-02, -2.88095400e-02, -2.70524565e-02,\n",
       "        1.02296725e-01,  7.52571896e-02, -2.59594414e-02, -2.65949555e-02,\n",
       "       -4.69846539e-02, -1.33360745e-02,  1.70475000e-03, -1.76358819e-02,\n",
       "       -4.12113890e-02,  3.39410640e-02,  3.59486081e-02, -3.41615230e-02,\n",
       "        9.15826485e-02, -6.70039058e-02,  4.86283824e-02, -2.68086325e-02,\n",
       "        3.78752202e-02,  8.08212347e-03,  4.23676968e-02,  1.52024049e-02,\n",
       "        1.58875920e-02, -3.11394781e-02, -8.78774077e-02, -5.79141900e-02,\n",
       "        2.41950918e-02,  2.57019303e-03, -7.73024336e-02,  1.55816805e-02,\n",
       "       -2.86607277e-02, -4.32956368e-02, -2.53818929e-02,  5.45954891e-02,\n",
       "        8.37033801e-03, -2.65179332e-02, -2.61619920e-03, -3.31445201e-03,\n",
       "       -1.79148819e-02, -2.60945894e-02,  4.77012806e-03, -5.08270115e-02,\n",
       "       -1.84851959e-02, -2.16279924e-02,  1.43807642e-02, -3.05946041e-02,\n",
       "        1.50616989e-02, -4.09028605e-02,  7.04844892e-02,  2.60001551e-02,\n",
       "       -8.37907754e-03, -6.81087524e-02, -1.92867480e-02,  2.49227174e-02,\n",
       "       -5.90110570e-03, -1.05722837e-01,  4.74699065e-02,  3.64244059e-02,\n",
       "       -3.45415361e-02,  9.81411780e-04,  1.11524444e-02, -4.03989619e-03,\n",
       "       -2.44927648e-02, -1.97279304e-02, -3.08720153e-02,  2.80873310e-02,\n",
       "        1.00117046e-02,  2.18961127e-02,  6.14455994e-03, -1.32056475e-02,\n",
       "       -5.07736579e-02, -1.97931603e-02,  8.27940367e-03, -4.62120585e-02,\n",
       "       -5.51684760e-02, -5.14608435e-02,  5.03852172e-03, -3.24241258e-02,\n",
       "        1.12097124e-02, -1.46342460e-02,  7.48953819e-02,  2.12575402e-02,\n",
       "        3.87335643e-02, -2.58958898e-02, -2.79744640e-02, -2.42690071e-02,\n",
       "        2.16051359e-02,  3.84969916e-03, -2.80154981e-02,  3.35135288e-03,\n",
       "        7.39866197e-02, -1.72764510e-02,  2.68466268e-02, -1.88286379e-02,\n",
       "       -3.92891020e-02, -6.49442291e-03, -1.54084973e-02, -2.65791044e-02,\n",
       "        9.35086831e-02,  3.82398977e-03, -2.68056318e-02, -1.05356043e-02,\n",
       "        2.97878217e-02, -2.91752219e-02,  2.86789145e-02,  5.40051982e-03,\n",
       "        5.71340211e-02, -3.11719328e-02, -1.92548297e-02,  8.66377577e-02,\n",
       "       -5.26125683e-03, -1.58109441e-02, -7.37259490e-03, -7.48096433e-33,\n",
       "       -8.16420186e-03,  1.73741858e-03, -2.53644008e-02, -5.03593823e-03,\n",
       "       -6.86859041e-02,  4.40038741e-02, -7.90443458e-03,  9.27459635e-03,\n",
       "        4.66299467e-02,  4.97320289e-05, -6.55424595e-03,  1.35525865e-02,\n",
       "        3.27868648e-02, -2.53598038e-02,  2.26442032e-02, -5.32447770e-02,\n",
       "        1.65595375e-02,  2.85723154e-02, -1.28313787e-02, -2.56135855e-02,\n",
       "       -6.18036501e-02, -1.92073639e-02,  2.91739944e-02,  4.81622145e-02,\n",
       "       -6.77685738e-02, -4.26128916e-02, -2.30916291e-02, -3.08419708e-02,\n",
       "       -4.77962717e-02, -1.71754826e-02, -2.17241012e-02,  5.16959913e-02,\n",
       "        3.26243863e-02,  2.61109043e-02, -2.66778469e-03,  4.86687347e-02,\n",
       "       -5.40457033e-02, -8.97556450e-03,  3.66165326e-03, -1.42301265e-02,\n",
       "       -9.21469256e-02, -2.49562617e-02, -1.05390034e-04, -7.45286094e-03,\n",
       "       -2.56973915e-02, -4.04446479e-03,  2.79512890e-02,  2.36190893e-02,\n",
       "       -1.93815418e-02,  9.34776664e-02,  5.30957850e-03, -1.87141187e-02,\n",
       "       -2.86967885e-02, -2.52439678e-02, -9.64601431e-03,  5.35384193e-02,\n",
       "        3.96264046e-02, -7.46777887e-03,  7.34483078e-03,  2.10735947e-03,\n",
       "        2.99707148e-02, -1.34609807e-02, -3.01808342e-02,  1.13324439e-02,\n",
       "        2.51599513e-02,  4.98912670e-03,  1.34255573e-01,  8.57840255e-02,\n",
       "       -2.42480412e-02,  5.10858255e-04,  3.55322240e-03, -1.30220428e-02,\n",
       "       -9.40548629e-03, -1.68338828e-02, -6.24424145e-02, -8.98142532e-02,\n",
       "        1.76630970e-02, -3.23512219e-02, -2.87888683e-02,  4.10667174e-02,\n",
       "       -2.74146232e-03,  3.16261151e-03,  3.54909450e-02, -1.42004024e-02,\n",
       "       -2.64342707e-02,  1.62269529e-02, -7.48077361e-03,  3.42454016e-02,\n",
       "       -2.49888990e-02, -4.16228408e-03,  1.17719984e-02, -4.00646441e-02,\n",
       "       -2.35405415e-02, -8.75221565e-03,  1.55821405e-02, -1.63654462e-02,\n",
       "       -3.57433073e-02,  1.19522829e-02,  7.34548038e-03,  2.15328149e-02,\n",
       "        3.83845866e-02, -8.30108859e-03,  3.02559454e-02,  1.07787717e-02,\n",
       "        2.01522317e-02,  1.84977073e-02,  3.61459167e-03,  4.61707599e-02,\n",
       "        5.21231703e-02, -5.31146154e-02, -3.89908329e-02,  1.90590061e-02,\n",
       "        1.48182083e-02,  4.29888442e-02,  4.00313828e-03,  5.57821020e-02,\n",
       "       -1.65058821e-02, -2.22848877e-02, -5.35408296e-02,  6.90800622e-02,\n",
       "       -2.79135909e-02,  4.08626627e-03, -2.01859884e-02, -4.04299609e-02,\n",
       "       -5.23086311e-03,  3.73510234e-02, -1.11761093e-02, -3.66712734e-02,\n",
       "       -2.87186960e-03,  2.10754666e-02,  3.76952849e-02,  1.09278159e-02,\n",
       "        2.34670424e-07, -5.83813852e-03, -1.06521659e-02,  4.90937568e-02,\n",
       "        1.93328410e-02, -1.56828053e-02, -1.16359983e-02, -5.01941657e-03,\n",
       "       -1.42203586e-03, -1.25967935e-02,  4.80137728e-02,  1.94739141e-02,\n",
       "       -9.63915547e-04,  9.95586161e-03, -2.91750557e-03,  1.02095477e-01,\n",
       "       -4.05393690e-02,  4.36692238e-02, -8.68652947e-03, -1.26141589e-02,\n",
       "        4.96187201e-03, -2.95747095e-03,  9.54299979e-03,  1.09062903e-02,\n",
       "       -1.48720182e-02,  1.88651085e-02,  9.85456556e-02, -1.29850013e-02,\n",
       "       -3.30950953e-02, -7.27010593e-02, -2.73238178e-02, -2.98812259e-02,\n",
       "        6.37464523e-02,  3.33134122e-02, -4.05681655e-02, -8.69690254e-03,\n",
       "       -7.63494000e-02,  7.29527250e-02, -1.63663120e-03,  3.26969139e-02,\n",
       "        3.76455160e-03, -7.44201615e-02, -2.90436600e-03, -1.64837223e-02,\n",
       "       -1.61299836e-02,  3.63584086e-02, -8.07746649e-02,  3.56798321e-02,\n",
       "        1.12884067e-01, -6.01822063e-02, -3.23757599e-03, -4.36222702e-02,\n",
       "       -8.07509106e-03,  1.59766525e-02,  1.50590632e-02, -1.09581305e-02,\n",
       "       -2.08811922e-04,  2.23354679e-02,  2.02780142e-02,  3.66384499e-02,\n",
       "        4.76100110e-02,  6.08531339e-03,  3.41525711e-02, -2.32867319e-02,\n",
       "       -1.81981213e-02, -5.39805703e-02, -5.15633076e-03, -5.87134808e-02,\n",
       "        4.48038179e-35,  2.38259081e-02, -2.66424883e-02,  2.49109939e-02,\n",
       "        5.19612953e-02,  1.65563170e-02,  1.88923907e-03, -3.42106596e-02,\n",
       "        2.48623081e-02,  4.11066823e-02, -4.45085578e-02, -3.00775096e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encode(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "19b3f374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encode(sentences[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d856e9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (0.3.25)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from langchain) (0.3.60)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from langchain) (0.3.42)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from langchain) (2.11.4)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from langchain) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (4.13.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from requests<3,>=2->langchain) (2.4.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (0.3.24)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.59 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from langchain-community) (0.3.60)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from langchain-community) (0.3.25)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from langchain-community) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from langchain-community) (3.11.18)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from langchain-community) (2.9.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from langchain-community) (0.3.42)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (0.3.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (2.11.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (4.13.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.59->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (0.4.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.4.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\chand\\anaconda3\\envs\\env\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n",
    "!pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ad5000be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "18afb0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model_name = \"sentence-transformers/all-mpnet-base-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f34b6d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chand\\anaconda3\\envs\\env\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\chand\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query embedding shape: 384\n",
      "Number of document embeddings: 2\n",
      "Each embedding vector length: 384\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Model name and configuration\n",
    "embedding_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "model_kwargs = {\"device\": \"cpu\"}  # or \"cuda\" if you have a GPU\n",
    "\n",
    "# Initialize the embedding model\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=embedding_model_name,\n",
    "    model_kwargs=model_kwargs\n",
    ")\n",
    "\n",
    "# Embed a single query\n",
    "query_embedding = embeddings.embed_query(\"I love programming in Python\")\n",
    "print(\"Query embedding shape:\", len(query_embedding))\n",
    "\n",
    "# Embed a list of documents\n",
    "docs = [\n",
    "    \"I love programming in Python\",\n",
    "    \"Python is a great language for data science\"\n",
    "]\n",
    "doc_embeddings = embeddings.embed_documents(docs)\n",
    "print(\"Number of document embeddings:\", len(doc_embeddings))\n",
    "print(\"Each embedding vector length:\", len(doc_embeddings[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cfb7c82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eb96faa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x22d1f82bd10>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "random_seed=42\n",
    "random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e7d85279",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chand\\anaconda3\\envs\\env\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\chand\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "tokenizer=BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d72765c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "model=BertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b46eebc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"follow krish and sunny savitha for genai learning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5f1705cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding=tokenizer.batch_encode_plus([text],padding=True,truncation=True,return_tensors=\"pt\",add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ed6709fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids=encoding[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7236b57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask=encoding[\"attention_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "62b6ea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  outputs=model(input_ids, attention_mask=attention_mask)\n",
    "  word_embeddings=outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "189a6ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2734, -0.1671,  0.1827,  ..., -0.1776,  0.1434,  0.2853],\n",
       "         [ 0.9149, -0.0324,  0.2213,  ...,  0.2632,  0.5265,  0.0233],\n",
       "         [ 0.5619, -1.2690,  0.0807,  ..., -0.9424,  0.0024, -1.2081],\n",
       "         ...,\n",
       "         [-0.1183, -0.4699, -0.2115,  ..., -0.4210, -0.2176, -0.3333],\n",
       "         [-0.5571, -0.7545, -0.2103,  ...,  0.7741,  0.5251, -0.4931],\n",
       "         [ 0.8210,  0.0588, -0.0103,  ...,  0.1527, -0.5460, -0.2349]]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8ec6955a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 14, 768])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fb69cfce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  101,  3582, 19031,  2232,  1998, 11559,  7842,  5737,  8322,  2005,\n",
       "         8991,  4886,  4083,   102])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e0931e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "decode=tokenizer.decode(input_ids[0],skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7cfd29af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'follow krish and sunny savitha for genai learning'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
